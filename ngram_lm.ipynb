{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections\n",
    "import pprint as pp\n",
    "\n",
    "class PreprocessReviews():\n",
    "    \"\"\"utility functions for adding special tokens to reviews\"\"\"\n",
    "    def __init__(self, data_path):\n",
    "        with open(data_path, 'r') as f:\n",
    "            self.data = f.readlines()\n",
    "\n",
    "    def get_counts(self, n):\n",
    "        token_counts = collections.Counter()\n",
    "        for line in self.data:\n",
    "            line = self.add_start_end(line, n)\n",
    "            line = self.sep_punct(line).split()\n",
    "            for token in line:\n",
    "                token_counts[token] += 1\n",
    "        return token_counts\n",
    "\n",
    "    def sep_punct(self, text):\n",
    "        text = text.replace('.', ' .').replace(',', ' ,').strip()\n",
    "        return text\n",
    "    \n",
    "    def add_start_end(self, text, n):\n",
    "        text = '<s> '* (n-1) + text + ' </s>'\n",
    "        return text\n",
    "    \n",
    "    def preprocess_text(self, n, add_unk, threshold):\n",
    "        preprocessed = []\n",
    "        if add_unk:\n",
    "            token_counts = self.get_counts(n)\n",
    "        for line in self.data:\n",
    "            line = self.add_start_end(line, n)\n",
    "            line = self.sep_punct(line).split()\n",
    "            if add_unk:\n",
    "                for idx, token in enumerate(line):\n",
    "                    if token_counts[token] <= threshold:\n",
    "                        line[idx] = '<unk>'\n",
    "            preprocessed.append(line)\n",
    "        return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "class Ngram_model():\n",
    "    \"\"\"class for ngram models when n > 1\n",
    "    can load and save parameters (probas) to a 'models' directory\"\"\"\n",
    "    def __init__(self, data_path, load=False, n=2, add_unk=False, threshold=1, output_dir='models'):\n",
    "        self.n = n \n",
    "        self.data_path = data_path\n",
    "        self.add_unk = add_unk\n",
    "        self.threshold = threshold\n",
    "        if not load:\n",
    "            self.proba_table = self.estimate_probas()\n",
    "        else:\n",
    "            self.load_probas(self.n)\n",
    "        self.output_dir = output_dir\n",
    "    \n",
    "    def prep_reviews(self):\n",
    "        prep = PreprocessReviews(self.data_path)\n",
    "        preprocessed = prep.preprocess_text(n=self.n, add_unk=self.add_unk, threshold=self.threshold)\n",
    "        return preprocessed\n",
    "    \n",
    "    def make_ngrams(self, line):\n",
    "        ngrams = []\n",
    "        for idx in range(len(line) - self.n + 1):\n",
    "            ngrams.append(tuple([line[idx+i] for i in range(self.n)]))\n",
    "        return ngrams\n",
    "\n",
    "    def estimate_probas(self):\n",
    "        proba_table = {}\n",
    "        preprocessed = self.prep_reviews()\n",
    "        for line in preprocessed:\n",
    "            ngrams = self.make_ngrams(line)\n",
    "            for ngram in ngrams:\n",
    "                n_minus1_gram = ngram[:-1]\n",
    "                next_w = ngram[-1]\n",
    "\n",
    "                next_w_counts = proba_table.get(n_minus1_gram, collections.defaultdict(int))\n",
    "\n",
    "                next_w_counts[next_w] += 1\n",
    "                proba_table[n_minus1_gram] = next_w_counts\n",
    "\n",
    "        for n_minus1_gram in proba_table:\n",
    "            next_w_counts = proba_table[n_minus1_gram]\n",
    "            next_word_probas = {key: value/(sum(next_w_counts.values())) for (key, value) in next_w_counts.items()}\n",
    "            proba_table[n_minus1_gram] = next_word_probas        \n",
    "    \n",
    "        return proba_table\n",
    "    \n",
    "    def save_probas(self):\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        with open(os.path.join(self.output_dir, f'proba_table_{self.n}-gram.pkl'), 'wb') as f:\n",
    "           pkl.dump(self.proba_table, f)\n",
    "\n",
    "    def load_probas(self):\n",
    "        with open(os.path.join(self.output_dir, f'proba_table_{self.n}-gram.pkl'), 'rb') as f:\n",
    "            self.proba_table = pkl.load(f)\n",
    "\n",
    "\n",
    "\n",
    "class Unigram_model(Ngram_model):\n",
    "    \"\"\"subclass of Ngram_model for unigram models\n",
    "    Inherits all methods and attributes from Ngram_model, but overrides estimate_probas method\"\"\"\n",
    "    def __init__(self, data_path, load=False, add_unk=False, threshold=1, output_dir='models'):\n",
    "        super().__init__(data_path, load=load, n=1, add_unk=add_unk, threshold=threshold, output_dir=output_dir)\n",
    "        \n",
    "    def estimate_probas(self):\n",
    "        # override inherited method\n",
    "        proba_table = collections.defaultdict(int)\n",
    "        preprocessed = self.prep_reviews()\n",
    "        for line in preprocessed:\n",
    "            unigrams = self.make_ngrams(line)\n",
    "            for uni in unigrams:\n",
    "                proba_table[uni[0]] += 1 # make_ngrams return tuples, so uni[0] is the unigram\n",
    "        proba_table = {key: value/(sum(proba_table.values())) for (key, value) in proba_table.items()}   \n",
    "    \n",
    "        return proba_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Review_generator():\n",
    "    \"\"\"loads a pre-trained ngram model and generates a review using the model\"\"\"\n",
    "    def __init__(self, n, dir_path='models'):\n",
    "        self.n = n\n",
    "        self.dir_path = dir_path\n",
    "        with open(os.path.join(dir_path, f'proba_table_{n}-gram.pkl'), 'rb') as f:\n",
    "            self.proba_table = pkl.load(f)\n",
    "    \n",
    "    def sample_from_discrete_distrib(self, distrib):\n",
    "        words, probas = zip(*distrib.items())\n",
    "        probas = np.asarray(probas).astype('float64')/np.sum(probas)\n",
    "        return np.random.choice(words, p=probas)\n",
    "    \n",
    "    def generate_review(self, max_length=20):\n",
    "        generated_sent = ['<s>']*(self.n-1)\n",
    "        w_i = None\n",
    "        while w_i != '</s>' and len(generated_sent) < max_length:\n",
    "            if self.n == 1:\n",
    "                w_i = self.sample_from_discrete_distrib(self.proba_table)\n",
    "                generated_sent += [w_i]\n",
    "            else:\n",
    "                h = tuple(generated_sent[-(self.n-1):])\n",
    "                w_i = self.sample_from_discrete_distrib(self.proba_table[h])\n",
    "                generated_sent += [w_i]\n",
    "        return f\"{' '.join(generated_sent)}\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perplexity():\n",
    "    \"\"\"loads a list of ngram models and computes the perplexity of a review using the models\"\"\"\n",
    "    def __init__(self, dir_path='models', max_order=4):\n",
    "        self.dir_path = dir_path\n",
    "        self.models = []\n",
    "        for model in os.listdir(dir_path):\n",
    "            if model.endswith('.pkl'):\n",
    "                with open(os.path.join(dir_path, model), 'rb') as f:\n",
    "                    if '1' in model:\n",
    "                        unigram_table = pkl.load(f)\n",
    "                    else:\n",
    "                        proba_table = pkl.load(f)\n",
    "                        self.models.append(proba_table)\n",
    "        self.models.sort(key=lambda table: len(list(table.keys())[0]), reverse=True) # from higher to lower order\n",
    "        self.models.append(unigram_table)\n",
    "        self.models = self.models[len(self.models)-max_order:] # keep only max order models if more loaded models than max_order\n",
    "        self.vocab = list(self.models[-1].keys())\n",
    "        self.vocab.extend(['<s>', '</s>', '<unk>'])\n",
    "       \n",
    "\n",
    "    def prep_single_review(self, review, n):\n",
    "        # check if token is in vocab otherwise replace with <unk>\n",
    "        review = review.replace('.', ' .').replace(',', ' ,').strip()\n",
    "        review = '<s> ' * (n - 1) + review + ' </s>'\n",
    "        review = review.split()\n",
    "        for idx, token in enumerate(review):\n",
    "            if token not in self.vocab:\n",
    "                review[idx] = '<unk>'\n",
    "        return review\n",
    "\n",
    "    def make_ngrams(self, review, n):\n",
    "        ngrams = []\n",
    "        for idx in range(len(review) - n + 1):\n",
    "            ngrams.append(tuple([review[idx + i] for i in range(n)]))\n",
    "        return ngrams\n",
    "    \n",
    "    def stupid_backoff(self, ngram, model_num=0):\n",
    "        if len(ngram) == 1:\n",
    "            return self.models[-1][ngram[0]] # break recursion if unigram\n",
    "        elif ngram[:-1] in self.models[model_num] and ngram[-1] in self.models[model_num][ngram[:-1]]:\n",
    "            return self.models[model_num][ngram[:-1]][ngram[-1]] # break recursion if ngram in model\n",
    "        return  .4 * self.stupid_backoff(ngram[1:], model_num+1) # otherwise recurse with discounted lower order model\n",
    "\n",
    "    def compute(self, review):\n",
    "        review = self.prep_single_review(review, n=len(self.models)) \n",
    "        ngrams = self.make_ngrams(review, n=len(self.models))  \n",
    "        log_proba = 0\n",
    "        for ngram in ngrams:\n",
    "            log_proba += np.log2(self.stupid_backoff(ngram))\n",
    "        perplexity = 2**(-log_proba/len(ngrams))\n",
    "        return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and save models from 1 to 4-gram\n",
    "for n in range(1, 5):\n",
    "    if n == 1:\n",
    "        model = Unigram_model('Prime_Pantry_train.txt', add_unk=True, threshold=1)\n",
    "    else:\n",
    "        model = Ngram_model('Prime_Pantry_train.txt', n=n, add_unk=True, threshold=1)\n",
    "    model.save_probas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1-gram review: <unk> to Now <unk> 25% see for don't Herbal on . . packaging until 6 is dreamed potty came Castile my Rating: range I teeth was car Excellent you few at 5 smooth take snacks , I of becomes time when dipped of instant my <unk> it have bag can\n",
      "Generated 2-gram review: <s> Rating: 5 . He really rich and fits into the texture of chemicals into a try this vs 4g . Live and one is smaller then season . and contents to be done until dinner but they make clearer on this is super <unk> batteries and cheese and biscuits\n",
      "Generated 3-gram review: <s> <s> Rating: 5 . Good source of fuel for road trips or hikes . They are chocolaty and not intending to give a five star review! Thank you . It is this is a category all its a must for fine , grainy texture - not exactly moisturizing .\n",
      "Generated 4-gram review: <s> <s> <s> Rating: 4 . This peanut butter changed my life . I don't care for the smell either . </s>\n"
     ]
    }
   ],
   "source": [
    "# generate random reviews\n",
    "# 4-grams can sometimes copy whole reviews from the training set\n",
    "for i in range(1,5):\n",
    "    r_gen = Review_generator(i)\n",
    "    r_gen.generate_review(max_length=50)\n",
    "    print(f\"Generated {i}-gram review: {r_gen.generate_review(max_length=50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average perplexity for 1-gram: 481.3763317904057\n",
      "Average perplexity for 2-gram: 36.174417121146334\n",
      "Average perplexity for 3-gram: 7.257191454049358\n",
      "Average perplexity for 4-gram: 3.0560696479099274\n"
     ]
    }
   ],
   "source": [
    "with open('Prime_Pantry_test.txt', 'r') as f:\n",
    "    test_reviews = f.readlines()\n",
    "\n",
    "for order in range(1, 5):\n",
    "    pp = Perplexity(max_order=order)\n",
    "    avg = np.mean([pp.compute(review) for review in test_reviews[:64]])\n",
    "    print(f\"Average perplexity for {order}-gram: {avg}\")\n",
    "    \n",
    "    # can also compute perplexity for new reviews not necessarily in the \"curated\" test set\n",
    "    # review = \"These are the best cookies I have ever had. So good that I have to hide them from my husband or he will eat them all.\"\n",
    "    # print(f\"Perplexity for {order}-gram: {pp.compute(review)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
